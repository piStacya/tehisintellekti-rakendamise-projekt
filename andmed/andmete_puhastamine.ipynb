{
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Andmete puhastamine\n\nSiin töötleme varasemas etapis kogutud toorandmeid (`toorandmed_aasta.csv`).\n\n**Sisend:** `toorandmed_aasta.csv`\n\n**Väljund:** `andmed_aasta.csv`\n\n### Samm 0: Teekide laadimine ja failiteede seadistamine\nLaeme vajalikud Pythoni teegid ja fikseerime sisend- ja väljundfailide asukohad. Loeme sisse puhastamata andmed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\nimport json\nimport numpy as np\nimport os\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', 100)\n\nINPUT_FILE = 'toorandmed_aasta.csv'\nOUTPUT_FILE = 'andmed_aasta.csv'\n\nif os.path.exists(INPUT_FILE):\n    df = pd.read_csv(INPUT_FILE, low_memory=False)\n    print(f\"Toorandmed loetud. Andmestiku suurus: {df.shape[0]} rida, {df.shape[1]} veergu.\")\nelse:\n    raise FileNotFoundError(f\"Viga: Sisendfaili '{INPUT_FILE}' ei leitud! Kontrolli failiteed.\")\n\ndf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samm 1: Eemaldame andmed, mida me ei taha\n\nFiltreerime välja read, mis ei sobi meie rakenduse jaoks:\n- **`additional_info__duration_in_semesters`** — viskame ära read, kus see on suurem kui 1\n- **`version__target__study_type__et`** — jätame ainult päevaõppe ained\n- **`general__type__et`** — jätame ainult tavalised ained (välistame praktikad, kaitsmised, kompleksained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Ridu enne filtreerimist: {len(df)}\")\n\nif 'additional_info__duration_in_semesters' in df.columns:\n    mask_duration = df['additional_info__duration_in_semesters'] <= 1\n    df = df[mask_duration]\n    print(f\"Pärast kestuse filtrit (<=1 semester): {len(df)} rida\")\n\nif 'version__target__study_type__et' in df.columns:\n    mask_study_type = df['version__target__study_type__et'].isna() | df['version__target__study_type__et'].str.contains('päevaõ', case=False, na=False)\n    df = df[mask_study_type]\n    print(f\"Pärast õppetüübi filtrit (päevaõpe): {len(df)} rida\")\n\nif 'general__type__et' in df.columns:\n    print(f\"general__type__et väärtused enne filtrit:\\n{df['general__type__et'].value_counts()}\")\n    mask_type = df['general__type__et'].str.contains('Tavaline', case=False, na=False)\n    df = df[mask_type]\n    print(f\"\\nPärast aine tüübi filtrit (Tavaline aine): {len(df)} rida\")\n\nprint(f\"\\nLõplik ridade arv pärast filtreerimist: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samm 2: Puhastatud veergude lisamine\n\nValime välja huvipakkuvad veerud ning puhastame need. Eelistame alati `version__` prefiksiga veerge, sest need kajastavad tegelikku aineprogrammi. Kui see puudub, võtame üldise info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_fields(df):\n    \"\"\"\n    Loob uued puhtad veerud, eelistades versiooni-põhist infot.\n    Tagastab täiendatud DataFrame'i.\n    \"\"\"\n    merge_mapping = [\n        ('nimi_et', 'title__et', 'version__title__et'),\n        ('nimi_en', 'title__en', 'version__title__en'),\n        ('eap', 'credits', 'version__credits'),\n        ('kirjeldus_et', 'overview__description__et', 'version__overview__description__et'),\n        ('kirjeldus_en', 'overview__description__en', 'version__overview__description__en'),\n        ('oppivaaljundid_en', 'overview__learning_outcomes_text_en', 'version__overview__learning_outcomes_text_en'),\n        ('oppivaaljundid_et', 'overview__learning_outcomes_text_et', 'version__overview__learning_outcomes_text_et'),\n        ('keel_et', 'version__target__language__et', None),\n        ('keel_en', 'version__target__language__en', None),\n    ]\n\n    rename_mapping = [\n        ('aine_kood', 'code'),\n        ('semester', 'version__target__semester__et'),\n        ('hindamisskaala', 'additional_info__assessment_scale__et'),\n        ('linn', 'version__target__course_main_structural_unit__city'),\n        ('hindamine', 'version__grading__grade_evaluation__et'),\n        ('taiskoormus', 'additional_info__is_continuous_learning_course'),\n        ('kestus_semestrites', 'additional_info__duration_in_semesters'),\n        ('oppe_tuup', 'version__target__study_type__et'),\n        ('aine_tuup', 'general__type__et'),\n        ('eeldusained_json', 'additional_info__prerequisites'),\n        ('oppeaste_json', 'version__additional_info__study_levels'),\n    ]\n\n    print(\"Alustan veergude filtreerimist ja ühendamist...\")\n\n    for new_col, base, version in merge_mapping:\n        base_exists = base in df.columns if base else False\n        ver_exists = version in df.columns if version else False\n        if base_exists and ver_exists:\n            df[new_col] = df[version].fillna(df[base])\n        elif ver_exists:\n            df[new_col] = df[version]\n        elif base_exists:\n            df[new_col] = df[base]\n        else:\n            df[new_col] = np.nan\n\n    for new_col, source in rename_mapping:\n        if source in df.columns:\n            df[new_col] = df[source]\n        else:\n            df[new_col] = np.nan\n\n    return df\n\ndf_resolved = resolve_fields(df.copy())\n\nprint(f\"Samm 2: Puhastatud veergude lisamine tehtud.\")\nprint(f\"\\nPuuduvate väärtuste arv uutes veergudes:\")\nnew_cols = ['aine_kood', 'nimi_et', 'nimi_en', 'eap', 'semester', 'kirjeldus_et', 'kirjeldus_en',\n            'oppivaaljundid_en', 'oppivaaljundid_et', 'keel_et', 'keel_en',\n            'hindamisskaala', 'linn', 'hindamine', 'taiskoormus',\n            'kestus_semestrites', 'oppe_tuup', 'aine_tuup',\n            'eeldusained_json', 'oppeaste_json']\nprint(df_resolved[new_cols].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samm 3: JSON väljade parsimine\n\nParsime 2 JSON veergu:\n- **Eeldusained** — eraldame ainete koodid ja nimetused\n- **Õppeaste** — eraldame taseme (bakalaureus, magister, doktor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_safe(json_str):\n    \"\"\"Teisendab JSON-stringi turvaliselt Pythoni objektiks.\"\"\"\n    if pd.isna(json_str) or json_str == '':\n        return None\n    try:\n        return json.loads(json_str)\n    except (json.JSONDecodeError, TypeError):\n        return None\n\ndef extract_prerequisites(json_str):\n    \"\"\"Eraldab eeldusainete koodid ja nimed.\"\"\"\n    data = parse_json_safe(json_str)\n    if not data: return None\n    courses = []\n    for item in data:\n        if not isinstance(item, dict): continue\n        code = item.get('code', '')\n        title_obj = item.get('title', {})\n        title = title_obj.get('et', title_obj.get('en', '')) if isinstance(title_obj, dict) else ''\n        if code and title:\n            courses.append(f\"{code} - {title}\")\n        for alt in item.get('alternatives', []):\n            if not isinstance(alt, dict): continue\n            alt_code = alt.get('code', '')\n            alt_title_obj = alt.get('title', {})\n            alt_title = alt_title_obj.get('et', alt_title_obj.get('en', '')) if isinstance(alt_title_obj, dict) else ''\n            if alt_code and alt_title:\n                courses.append(f\"{alt_code} - {alt_title}\")\n    return \"; \".join(courses) if courses else None\n\ndef extract_study_levels(json_str):\n    \"\"\"Eraldab õppeastme nimetused eesti keeles.\"\"\"\n    data = parse_json_safe(json_str)\n    if not data: return None\n    levels = []\n    for item in data:\n        if not isinstance(item, dict): continue\n        level_et = item.get('et', item.get('en', ''))\n        if level_et:\n            levels.append(level_et)\n    return \", \".join(levels) if levels else None\n\nprint(\"Ekstraheerime JSON väljadest infot...\")\ndf_resolved['eeldusained'] = df_resolved['eeldusained_json'].apply(extract_prerequisites)\ndf_resolved['oppeaste'] = df_resolved['oppeaste_json'].apply(extract_study_levels)\n\nprint(\"Samm 3: JSON töötlemine valmis.\\n\")\nprint(df_resolved[['aine_kood', 'eeldusained', 'oppeaste']].dropna(subset=['eeldusained']).head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samm 4: Info koondamine mitmest allikast\n\nKoondame hindamisinfo mitmest veerust üheks tekstiks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grading_source_cols = [\n    ('Miinimumnõuded', 'version__grading__grade_preconditions__et'),\n    ('Hindamismeetod', 'version__grading__grade_evaluation__et')\n]\n\ndef combine_grading_info(row):\n    \"\"\"Koondab hindamisinfo mitmest veerust üheks tekstiks.\"\"\"\n    parts = []\n    for label, col in grading_source_cols:\n        val = row.get(col)\n        if pd.notna(val) and str(val).strip():\n            parts.append(f\"{label}: {str(val).strip()}\")\n    return \"\\n\".join(parts) if parts else None\n\ndf_resolved['hindamine_info'] = df_resolved.apply(combine_grading_info, axis=1)\nprint(\"Samm 4: Hindamisinfo koondatud.\")\nprint(f\"Puuduvaid väärtusi: {df_resolved['hindamine_info'].isna().sum()}\")\nprint(f\"\\nNäide:\")\nsample = df_resolved['hindamine_info'].dropna().iloc[0]\nprint(sample[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samm 5: Lõplik viimistlus\n\nValime lõplikud veerud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = [\n    'aine_kood', 'nimi_et', 'nimi_en', 'eap', 'semester',\n    'keel_et', 'keel_en', 'linn', 'oppeaste', 'hindamisskaala',\n    'kirjeldus_et', 'kirjeldus_en',\n    'oppivaaljundid_et', 'oppivaaljundid_en',\n    'hindamine_info', 'eeldusained',\n    'taiskoormus', 'kestus_semestrites', 'oppe_tuup', 'aine_tuup'\n]\n\nexisting_cols = [c for c in final_cols if c in df_resolved.columns]\ndf_final = df_resolved[existing_cols].copy()\n\nprint(f\"Lõplik ridade arv: {len(df_final)}, lõplik veergude arv: {len(df_final.columns)}\")\nprint(f\"Veerud: {list(df_final.columns)}\")\nprint(\"Samm 5: Lõplik andmestik koostatud.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samm 6: Salvestamine ja kontroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(OUTPUT_FILE, index=False)\nprint(f\"Andmestik salvestatud faili '{OUTPUT_FILE}'.\\n\")\n\nprint(\"=\" * 60)\nprint(\"PUUDUVATE VÄÄRTUSTE HULK IGAS VEERUS\")\nprint(\"=\" * 60)\nmissing = df_final.isnull().sum()\ntotal = len(df_final)\nmissing_pct = (missing / total * 100).round(1)\nmissing_df = pd.DataFrame({'Puuduvaid': missing, 'Protsent (%)': missing_pct})\nprint(missing_df)\nprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\nprint(\"KATEGOORILISTE TUNNUSTE ENIM LEVINUD VÄÄRTUSED\")\nprint(\"=\" * 60)\n\ncategorical_cols = ['keel_et', 'semester', 'oppeaste', 'hindamisskaala', 'linn',\n                    'taiskoormus', 'kestus_semestrites', 'oppe_tuup', 'aine_tuup']\n\nfor col in categorical_cols:\n    if col in df_final.columns:\n        print(f\"\\n--- {col} ---\")\n        print(df_final[col].value_counts().head(5))\n        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\nprint(\"AINE: SISSEJUHATUS ANDMETEADUSESSE\")\nprint(\"=\" * 60)\n\nmask = df_final['nimi_et'].str.contains('Sissejuhatus andmeteadusesse', case=False, na=False)\nsissejuhatus = df_final[mask]\n\nif len(sissejuhatus) == 0:\n    print(\"Ainet 'Sissejuhatus andmeteadusesse' ei leitud! Proovime laiema otsinguga...\")\n    mask = df_final['nimi_et'].str.contains('andmeteadus', case=False, na=False)\n    sissejuhatus = df_final[mask]\n\nif len(sissejuhatus) > 0:\n    row = sissejuhatus.iloc[0]\n    line = chr(9472) * 50\n    print(f\"\\n{line}\")\n    print(f\"  Aine kood:        {row.get('aine_kood', 'N/A')}\")\n    print(f\"  Nimi (ET):        {row.get('nimi_et', 'N/A')}\")\n    print(f\"  Nimi (EN):        {row.get('nimi_en', 'N/A')}\")\n    print(f\"  EAP:              {row.get('eap', 'N/A')}\")\n    print(f\"  Semester:         {row.get('semester', 'N/A')}\")\n    print(f\"  Keel:             {row.get('keel_et', 'N/A')}\")\n    print(f\"  Linn:             {row.get('linn', 'N/A')}\")\n    print(f\"  Õppeaste:         {row.get('oppeaste', 'N/A')}\")\n    print(f\"  Hindamisskaala:   {row.get('hindamisskaala', 'N/A')}\")\n    print(f\"  Täiskoormus:      {row.get('taiskoormus', 'N/A')}\")\n    print(f\"  Kestus (sem.):    {row.get('kestus_semestrites', 'N/A')}\")\n    print(f\"  Õppe tüüp:        {row.get('oppe_tuup', 'N/A')}\")\n    print(f\"  Aine tüüp:        {row.get('aine_tuup', 'N/A')}\")\n    print(f\"  Eeldusained:      {row.get('eeldusained', 'N/A')}\")\n    print(f\"{line}\")\n    print(f\"\\n  Kirjeldus (ET):\")\n    print(f\"  {row.get('kirjeldus_et', 'N/A')}\")\n    print(f\"\\n  Kirjeldus (EN):\")\n    print(f\"  {row.get('kirjeldus_en', 'N/A')}\")\n    print(f\"\\n  Õpiväljundid (ET):\")\n    print(f\"  {row.get('oppivaaljundid_et', 'N/A')}\")\n    print(f\"\\n  Õpiväljundid (EN):\")\n    print(f\"  {row.get('oppivaaljundid_en', 'N/A')}\")\n    print(f\"\\n  Hindamise info:\")\n    print(f\"  {row.get('hindamine_info', 'N/A')}\")\n    print(f\"{line}\")\nelse:\n    print(\"Ainet ei leitud andmestikust.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\nprint(\"TUNNUSE 'KIRJELDUS' LOOMINE JA STATISTIKA\")\nprint(\"=\" * 60)\n\ndef build_kirjeldus(row):\n    \"\"\"Ühendab kõik aine veerud üheks suureks tekstiks RAGi jaoks.\"\"\"\n    parts = []\n    if pd.notna(row.get('nimi_et')): parts.append(f\"Aine: {row['nimi_et']}\")\n    if pd.notna(row.get('nimi_en')): parts.append(f\"Course: {row['nimi_en']}\")\n    if pd.notna(row.get('aine_kood')): parts.append(f\"Kood: {row['aine_kood']}\")\n    if pd.notna(row.get('eap')): parts.append(f\"EAP: {row['eap']}\")\n    if pd.notna(row.get('semester')): parts.append(f\"Semester: {row['semester']}\")\n    if pd.notna(row.get('keel_et')): parts.append(f\"Keel: {row['keel_et']}\")\n    if pd.notna(row.get('linn')): parts.append(f\"Linn: {row['linn']}\")\n    if pd.notna(row.get('oppeaste')): parts.append(f\"Õppeaste: {row['oppeaste']}\")\n    if pd.notna(row.get('hindamisskaala')): parts.append(f\"Hindamisskaala: {row['hindamisskaala']}\")\n    if pd.notna(row.get('kestus_semestrites')): parts.append(f\"Kestus semestrites: {row['kestus_semestrites']}\")\n    if pd.notna(row.get('oppe_tuup')): parts.append(f\"Õppe tüüp: {row['oppe_tuup']}\")\n    if pd.notna(row.get('aine_tuup')): parts.append(f\"Aine tüüp: {row['aine_tuup']}\")\n    if pd.notna(row.get('kirjeldus_et')): parts.append(f\"Kirjeldus: {row['kirjeldus_et']}\")\n    if pd.notna(row.get('kirjeldus_en')): parts.append(f\"Description: {row['kirjeldus_en']}\")\n    if pd.notna(row.get('oppivaaljundid_et')): parts.append(f\"Õpiväljundid: {row['oppivaaljundid_et']}\")\n    if pd.notna(row.get('oppivaaljundid_en')): parts.append(f\"Learning outcomes: {row['oppivaaljundid_en']}\")\n    if pd.notna(row.get('hindamine_info')): parts.append(f\"Hindamine: {row['hindamine_info']}\")\n    if pd.notna(row.get('eeldusained')): parts.append(f\"Eeldusained: {row['eeldusained']}\")\n    return \"\\n\".join(parts)\n\ndf_final['kirjeldus'] = df_final.apply(build_kirjeldus, axis=1)\ndf_final['kirjeldus_pikkus'] = df_final['kirjeldus'].str.len()\n\nprint(\"\\nTunnuse 'kirjeldus' tähemärkide arvu statistika:\")\nprint(df_final['kirjeldus_pikkus'].describe())\n\nprint(f\"\\nNäide (esimene aine):\")\nprint(df_final['kirjeldus'].iloc[0][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(10, 5))\ndf_final['kirjeldus_pikkus'].hist(bins=50, ax=ax, edgecolor='black')\nax.set_xlabel('Tähemärkide arv')\nax.set_ylabel('Ainete arv')\nax.set_title('Tunnuse \"kirjeldus\" pikkuse jaotus')\nax.axvline(df_final['kirjeldus_pikkus'].median(), color='red', linestyle='--', label=f\"Mediaan: {df_final['kirjeldus_pikkus'].median():.0f}\")\nax.axvline(df_final['kirjeldus_pikkus'].mean(), color='orange', linestyle='--', label=f\"Keskmine: {df_final['kirjeldus_pikkus'].mean():.0f}\")\nax.legend()\nplt.tight_layout()\nplt.show()\n\ndf_final.drop(columns=['kirjeldus_pikkus']).to_csv(OUTPUT_FILE, index=False)\nprint(f\"Lõplik andmestik salvestatud faili '{OUTPUT_FILE}' ({len(df_final)} rida, {len(df_final.columns) - 1} veergu).\")"
   ]
  }
 ]
}